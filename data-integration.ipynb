{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Integration with Jupyter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we want to explore, how Jupyter can be used to process and integrate data from various sources. Our data set consist of publicly available data from the EU about funded projects in the Horizon 2020 program, which is publicly available as CSV. We will add population data provided by the World Bank, mainly because it is available in XML. \n",
    "\n",
    "Here are the download links:\n",
    "\n",
    "- [Project data](https://data.europa.eu/euodp/de/data/dataset/cordisH2020projects/resource/010f269b-9ee3-45a0-afea-c43aa1ef61ac), [CSV file](http://cordis.europa.eu/data/cordis-h2020projects.csv)\n",
    "- [Project publication data](https://data.europa.eu/euodp/de/data/dataset/cordisH2020projects/resource/e3e6a3d5-6c67-4fca-b4fa-397e6a888300), [CSV file](http://cordis.europa.eu/data/cordis-h2020projectPublications.csv)\n",
    "- [Population data](https://data.worldbank.org/indicator/SP.POP.TOTL), [zipped XML](http://api.worldbank.org/v2/en/indicator/SP.POP.TOTL?downloadformat=xml)\n",
    "- [Country Codes ISO](https://datahub.io/core/country-codes), [JSON file](https://datahub.io/core/country-codes/r/country-codes.json)\n",
    "- [Country Codes EU](https://data.europa.eu/euodp/en/data/dataset/cordisref-data/resource/40e08e83-6cf3-4bf0-afe8-d84543186dfc), [CSV file](http://cordis.europa.eu/data/reference/cordisref-countries.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and preparation\n",
    "\n",
    "First, we will import all modules that we need. When we realize that we need another module, we include it here at the beginning of the notebook as well. This way, we always can easily see what the requirements of the notebook are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import collections\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we open the file and print the first line. This way, we see, if headers in the file are present and what field delimiter is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rcn;id;acronym;status;programme;topics;frameworkProgramme;title;startDate;endDate;projectUrl;objective;totalCost;ecMaxContribution;call;fundingScheme;coordinator;coordinatorCountry;participants;participantCountries;subjects\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data/cordis-h2020projects.csv\", \"r\", encoding='utf-8', newline=\"\")\n",
    "print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we probably want to read through the file several times (we don't care about performance, don't we...), we define a function that puts the file cursor back at the beginning of the file and creates a new CSV [DictReader](https://docs.python.org/3/library/csv.html#csv.DictReader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_reset():\n",
    "    global reader\n",
    "    f.seek(0)\n",
    "    reader = csv.DictReader(f, delimiter=\";\", )\n",
    "file_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'UK': 4313, 'ES': 3062, 'DE': 2748, 'FR': 2356, 'IT': 2215, 'NL': 1725, 'CH': 940, 'BE': 932, 'DK': 838, 'SE': 761, 'IL': 666, 'AT': 662, 'IE': 576, 'FI': 510, 'PT': 472, 'EL': 456, 'NO': 451, 'PL': 235, 'HU': 169, 'CZ': 139, 'TR': 139, 'SI': 137, 'EE': 134, 'CY': 107, 'IS': 106, 'RO': 72, 'LT': 62, 'SK': 57, 'LU': 54, 'BG': 49, 'RS': 44, 'LV': 41, 'HR': 35, 'MT': 27, 'UA': 21, 'BA': 8, 'FO': 7, 'AM': 6, 'MK': 6, 'TN': 6, 'MD': 5, 'ME': 4, 'KE': 2, 'GE': 1, 'CL': 1, 'GL': 1, 'US': 1, 'AI': 1, 'ZA': 1, 'UY': 1})\n",
      "Overall number of rows: 25362\n"
     ]
    }
   ],
   "source": [
    "overall = 0\n",
    "coordinator = collections.Counter()\n",
    "for rn, row in enumerate(reader):\n",
    "    overall += 1\n",
    "    if 'coordinatorCountry' in row:\n",
    "        coordinator[row[\"coordinatorCountry\"]] += 1\n",
    "    else:\n",
    "        print('Row {}: No coordinator country.'.format(rn))\n",
    "print(coordinator)\n",
    "print('Overall number of rows: {}'.format(overall))\n",
    "file_reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first research question\n",
    "\n",
    "What country has the most coordinators per capita, i.e., relative to its overall population?\n",
    "\n",
    "This question can be answered with the data from the world bank. Please have the XML file unzipped in your data folder.\n",
    "\n",
    "Again, we have a quick look at the actual file, this time the first 10 lines. Don't forget to reset to the beginning of the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<Root xmlns:wb=\"http://www.worldbank.org\">\n",
      "  <data>\n",
      "    <record>\n",
      "      <field name=\"Country or Area\" key=\"ABW\">Aruba</field>\n",
      "      <field name=\"Item\" key=\"SP.POP.TOTL\">Population, total</field>\n",
      "      <field name=\"Year\">1960</field>\n",
      "      <field name=\"Value\">54211</field>\n",
      "    </record>\n",
      "    <record>\n"
     ]
    }
   ],
   "source": [
    "popfile = open(\"data/API_SP.POP.TOTL_DS2_en_xml_v2_151522.xml\", 'r', encoding='utf-8', newline=\"\")\n",
    "for l in range(10):\n",
    "    print(popfile.readline().rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, unfortunately, there is a problem with this dataset, it uses three letter ISO country codes, while our EU dataset uses two letter EU-specific codes. Why can't data not be more homogenous...\n",
    "\n",
    "But fear not, we will also bridge this gap, of course by accessing even more data. This time, we use the data provided by datahub.io, and to see one more format, we use the JSON version. This gets us two letter ISO codes. With one more CSV file, we can obtain EU codes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United Kingdom two letter ISO: GB\n",
      "United Kingdom two letter EU: UK\n"
     ]
    }
   ],
   "source": [
    "cc = json.load(open('data/country-codes.json', 'r', encoding='utf-8'))\n",
    "iso2 = {}\n",
    "for c in cc:\n",
    "    iso2[c['ISO3166-1-Alpha-3']] = c['ISO3166-1-Alpha-2']\n",
    "    \n",
    "# Now, we can easily look up 2 letter codes by means of a 3 letter code\"\n",
    "print(\"United Kingdom two letter ISO:\", iso2['GBR'])\n",
    "\n",
    "eu = {}\n",
    "eucc = {} \n",
    "eucc_file = open('data/cordisref-countries.csv', 'r', encoding='utf-8-sig')\n",
    "for c in csv.DictReader(eucc_file, delimiter=';'):\n",
    "    eucc[c['isoCode']] = c['euCode']\n",
    "\n",
    "print(\"United Kingdom two letter EU:\", eucc[iso2['GBR']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our population data. Next, we parse the XML. As we can see the structure above, this is fairly straight-forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we read already some line, reset the file cursor\n",
    "popfile.seek(0)\n",
    "# data is within the first child node of the root node.\n",
    "data = ET.parse(popfile).getroot()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AM': 2951776,\n",
       " 'AT': 8847037,\n",
       " 'BE': 11422068,\n",
       " 'BG': 7024216,\n",
       " 'BA': 3323929,\n",
       " 'CH': 8516543,\n",
       " 'CL': 18729160,\n",
       " 'CY': 1189265,\n",
       " 'CZ': 10625695,\n",
       " 'DE': 82927922,\n",
       " 'DK': 5797446,\n",
       " 'ES': 46723749,\n",
       " 'EE': 1320884,\n",
       " 'FI': 5518050,\n",
       " 'FR': 66987244,\n",
       " 'FO': 48497,\n",
       " 'UK': 66488991,\n",
       " 'GE': 3731000,\n",
       " 'EL': 10727668,\n",
       " 'GL': 56025,\n",
       " 'HR': 4089400,\n",
       " 'HU': 9768785,\n",
       " 'IE': 4853506,\n",
       " 'IS': 353574,\n",
       " 'IL': 8883800,\n",
       " 'IT': 60431283,\n",
       " 'KE': 51393010,\n",
       " 'LT': 2789533,\n",
       " 'LU': 607728,\n",
       " 'LV': 1926542,\n",
       " 'MD': 3545883,\n",
       " 'MK': 2082958,\n",
       " 'MT': 483530,\n",
       " 'ME': 622345,\n",
       " 'NL': 17231017,\n",
       " 'NO': 5314336,\n",
       " 'PL': 37978548,\n",
       " 'PT': 10281762,\n",
       " 'RO': 19473936,\n",
       " 'RS': 6982084,\n",
       " 'SK': 5447011,\n",
       " 'SI': 2067372,\n",
       " 'SE': 10183175,\n",
       " 'TN': 11565204,\n",
       " 'TR': 82319724,\n",
       " 'UA': 44622516,\n",
       " 'UY': 3449299,\n",
       " 'US': 327167434,\n",
       " 'ZA': 57779622}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pops = {}\n",
    "for child in data:\n",
    "    if child.find(\"field[@name='Year']\").text == '2018':\n",
    "        ccode3 = child.find(\"field[@name='Country or Area']\").get('key')\n",
    "        if ccode3 in iso2:\n",
    "            ccode2 = eucc[iso2[ccode3]]\n",
    "        else:\n",
    "            # This is an area, we can proceed to next child\n",
    "            continue\n",
    "        if ccode2 in coordinator:\n",
    "            pop = int(child.find(\"field[@name='Value']\").text)\n",
    "            pops[ccode2] = pop\n",
    "pops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can answer our question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No population data for AI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('IS', 299.79579946489275),\n",
       " ('DK', 144.54640888418797),\n",
       " ('FO', 144.33882508196385),\n",
       " ('IE', 118.67709651538496),\n",
       " ('CH', 110.37342264343643),\n",
       " ('EE', 101.44721262427284),\n",
       " ('NL', 100.11016761227734),\n",
       " ('FI', 92.42395411422514),\n",
       " ('CY', 89.9715370417863),\n",
       " ('LU', 88.85554063660058),\n",
       " ('NO', 84.86478837619602),\n",
       " ('BE', 81.5964324498856),\n",
       " ('IL', 74.96791913370404),\n",
       " ('AT', 74.82731224024495),\n",
       " ('SE', 74.73111284054335),\n",
       " ('SI', 66.26770605386936),\n",
       " ('ES', 65.53412484088125),\n",
       " ('UK', 64.8678816617927),\n",
       " ('MT', 55.83934812731371),\n",
       " ('PT', 45.906528472454426),\n",
       " ('EL', 42.506908304768565),\n",
       " ('IT', 36.65320162075658),\n",
       " ('FR', 35.17087521916859),\n",
       " ('DE', 33.13721040785274),\n",
       " ('LT', 22.2259424785439),\n",
       " ('LV', 21.281653864800248),\n",
       " ('GL', 17.8491744756805),\n",
       " ('HU', 17.300001996154077),\n",
       " ('CZ', 13.081497257355872),\n",
       " ('SK', 10.464454725720216),\n",
       " ('HR', 8.558712769599452),\n",
       " ('BG', 6.975867484712885),\n",
       " ('ME', 6.427303183925314),\n",
       " ('RS', 6.3018434037745745),\n",
       " ('PL', 6.187703647859313),\n",
       " ('RO', 3.697249492860611),\n",
       " ('MK', 2.8805189542948058),\n",
       " ('BA', 2.4067902774096557),\n",
       " ('AM', 2.0326745660917362),\n",
       " ('TR', 1.6885382171592314),\n",
       " ('MD', 1.4100860067858978),\n",
       " ('TN', 0.5187975931942057),\n",
       " ('UA', 0.47061443151255744),\n",
       " ('UY', 0.28991397962310606),\n",
       " ('GE', 0.2680246582685607),\n",
       " ('CL', 0.05339267751463493),\n",
       " ('KE', 0.03891579808226838),\n",
       " ('ZA', 0.017307139877100614),\n",
       " ('US', 0.003056538934128756)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord_percap = collections.Counter()\n",
    "for c in coordinator:\n",
    "    if c not in pops:\n",
    "        print(\"No population data for\", c)\n",
    "        continue\n",
    "    coord_percap[c] = coordinator[c] / pops[c] * 1000000    \n",
    "coord_percap.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
